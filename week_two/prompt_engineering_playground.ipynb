{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prompt Engineering Playground\n",
        "\n",
        "This notebook demonstrates various prompting techniques including:\n",
        "- **Zero-shot prompting**: Direct instructions with no examples\n",
        "- **Few-shot prompting**: Including examples to guide the model\n",
        "- **Chain-of-thought prompting**: Encouraging step-by-step reasoning\n",
        "\n",
        "These techniques are applied to diverse tasks:\n",
        "- Arithmetic problems\n",
        "- Text rephrasing\n",
        "- Content summarization\n",
        "- Classification tasks\n",
        "\n",
        "## Setup Requirements\n",
        "\n",
        "1. Make sure you have a `.env` file with your `GEMINI_API_KEY`\n",
        "2. Install required packages using the cell below\n",
        "3. Restart the kernel if needed after installing packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-genai in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.19.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.1.0)\n",
            "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (2.2.3)\n",
            "Requirement already satisfied: matplotlib in /home/codespace/.local/lib/python3.12/site-packages (3.10.1)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /home/codespace/.local/lib/python3.12/site-packages (from google-genai) (4.9.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google-genai) (2.40.3)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /home/codespace/.local/lib/python3.12/site-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google-genai) (2.11.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /home/codespace/.local/lib/python3.12/site-packages (from google-genai) (2.32.3)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /home/codespace/.local/lib/python3.12/site-packages (from google-genai) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n",
            "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "%pip install google-genai python-dotenv pandas matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.84.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (2.11.5)\n",
            "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Current working directory: /workspaces/GenAI-developer-upskilling-track\n",
            "Files in current directory: ['week_one', 'week_three', 'week_one_sdk', '.git', 'week_two', '.gitignore']\n",
            "✓ dotenv loaded successfully (found: False)\n",
            "❌ .env file not found in current directory\n",
            "✓ API key set directly from script\n",
            "API key check: Found\n",
            "API key preview: AIzaSyBNYy...lXEs\n",
            "✓ Gemini client initialized successfully.\n",
            "\n",
            "🚀 Setup complete! Gemini client is ready for prompt engineering.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Current working directory: /workspaces/GenAI-developer-upskilling-track\n",
            "Files in current directory: ['week_one', 'week_three', 'week_one_sdk', '.git', 'week_two', '.gitignore']\n",
            "✓ dotenv loaded successfully (found: False)\n",
            "❌ .env file not found in current directory\n",
            "✓ API key set directly from script\n",
            "API key check: Found\n",
            "API key preview: AIzaSyBNYy...lXEs\n",
            "✓ Gemini client initialized successfully.\n",
            "\n",
            "🚀 Setup complete! Gemini client is ready for prompt engineering.\n",
            "✓ Test API call successful: Hi.\n",
            "\n",
            "✓ Test API call successful: Hi.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%pip install openai\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from typing import Dict, List, Union, Optional\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Import Gemini API\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from google.genai.errors import ServerError\n",
        "\n",
        "# Debug: Check current working directory\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n",
        "print(f\"Files in current directory: {os.listdir('.')}\")\n",
        "\n",
        "# Load environment variables\n",
        "try:\n",
        "    from dotenv import load_dotenv\n",
        "    # Try to load from multiple possible locations\n",
        "    env_loaded = load_dotenv()  # Load from current directory\n",
        "    if not env_loaded:\n",
        "        env_loaded = load_dotenv('../.env')  # Try parent directory\n",
        "    if not env_loaded:\n",
        "        env_loaded = load_dotenv('.env')  # Try explicit .env file\n",
        "    print(f\"✓ dotenv loaded successfully (found: {env_loaded})\")\n",
        "except ImportError:\n",
        "    print(\"⚠️ dotenv not installed. Using environment variables directly.\")\n",
        "\n",
        "# Check for .env file in current directory\n",
        "if os.path.exists('.env'):\n",
        "    print(\"✓ .env file found in current directory\")\n",
        "    with open('.env', 'r') as f:\n",
        "        content = f.read()\n",
        "        print(f\"✓ .env file content: {content[:50]}...\")\n",
        "else:\n",
        "    print(\"❌ .env file not found in current directory\")\n",
        "    # Let's try to set the API key directly for now\n",
        "    print(\"✓ API key set directly from script\")\n",
        "\n",
        "# Initialize the Gemini client\n",
        "gemini_api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
        "client = None  # Global client variable\n",
        "\n",
        "print(f\"API key check: {'Found' if gemini_api_key else 'Not found'}\")\n",
        "if gemini_api_key:\n",
        "    print(f\"API key preview: {gemini_api_key[:10]}...{gemini_api_key[-4:]}\")\n",
        "\n",
        "if not gemini_api_key:\n",
        "    print(\"❌ Warning: GEMINI_API_KEY not found in environment variables.\")\n",
        "    print(\"Please set your API key in a .env file or environment variable.\")\n",
        "    print(\"Example .env file content: GEMINI_API_KEY=your_actual_api_key_here\")\n",
        "else:\n",
        "    try:\n",
        "        client = genai.Client(api_key=gemini_api_key)\n",
        "        print(\"✓ Gemini client initialized successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error initializing Gemini client: {e}\")\n",
        "        print(\"API calls will likely fail.\")\n",
        "\n",
        "# Function to handle API calls with retry logic\n",
        "def get_completion(\n",
        "    prompt: str, \n",
        "    model: str = \"gemini-2.0-flash\",\n",
        "    temperature: float = 0,\n",
        "    max_retries: int = 3,\n",
        "    retry_delay: int = 2\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Send a prompt to the Gemini API and get a completion.\n",
        "    \n",
        "    Args:\n",
        "        prompt: The prompt to send to the API\n",
        "        model: The model to use (e.g., \"gemini-2.0-flash\", \"gemini-1.5-flash\")\n",
        "        temperature: Controls randomness (0=deterministic, 1=creative)\n",
        "        max_retries: Maximum number of retry attempts\n",
        "        retry_delay: Delay between retries in seconds\n",
        "        \n",
        "    Returns:\n",
        "        The completion text\n",
        "    \"\"\"\n",
        "    if client is None:\n",
        "        return \"❌ Error: Gemini client is not initialized. Check GEMINI_API_KEY.\"\n",
        "    \n",
        "    contents = [\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[types.Part.from_text(text=prompt)],\n",
        "        ),\n",
        "    ]\n",
        "    \n",
        "    generate_content_config = types.GenerateContentConfig(\n",
        "        response_mime_type=\"text/plain\",\n",
        "        temperature=temperature,\n",
        "    )\n",
        "    \n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response_text = \"\"\n",
        "            for chunk in client.models.generate_content_stream(\n",
        "                model=model,\n",
        "                contents=contents,\n",
        "                config=generate_content_config,\n",
        "            ):\n",
        "                response_text += chunk.text\n",
        "            return response_text\n",
        "            \n",
        "        except ServerError as e:\n",
        "            if e.status_code == 503 and attempt < max_retries - 1:\n",
        "                print(f\"⚠️ Server overloaded (503). Retrying in {retry_delay} seconds...\")\n",
        "                time.sleep(retry_delay)\n",
        "                retry_delay *= 2  # Exponential backoff\n",
        "            else:\n",
        "                return f\"❌ Failed after {max_retries} attempts: {e}\"\n",
        "        except Exception as e:\n",
        "            if attempt < max_retries - 1:\n",
        "                print(f\"⚠️ Error: {e}. Retrying in {retry_delay} seconds...\")\n",
        "                time.sleep(retry_delay)\n",
        "            else:\n",
        "                return f\"❌ Error: Could not get completion from API: {e}\"\n",
        "\n",
        "if client:\n",
        "    print(\"\\n🚀 Setup complete! Gemini client is ready for prompt engineering.\")\n",
        "    # Test the connection\n",
        "    test_response = get_completion(\"Say hello in one word.\")\n",
        "    print(f\"✓ Test API call successful: {test_response}\")\n",
        "else:\n",
        "    print(\"\\n❌ Setup incomplete. Please configure your GEMINI_API_KEY.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PromptTemplate:\n",
        "    def __init__(\n",
        "        self, \n",
        "        template: str, \n",
        "        input_variables: List[str] = None,\n",
        "        template_type: str = \"zero-shot\"\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize a prompt template.\n",
        "        \n",
        "        Args:\n",
        "            template: The template string with placeholders for variables\n",
        "            input_variables: List of variable names in the template\n",
        "            template_type: Type of prompt (zero-shot, few-shot, chain-of-thought)\n",
        "        \"\"\"\n",
        "        self.template = template\n",
        "        self.input_variables = input_variables or []\n",
        "        self.template_type = template_type\n",
        "        self.results = []\n",
        "        \n",
        "    def format(self, **kwargs) -> str:\n",
        "        \"\"\"\n",
        "        Format the template with the given variables.\n",
        "        \n",
        "        Args:\n",
        "            **kwargs: The variables to substitute into the template\n",
        "            \n",
        "        Returns:\n",
        "            The formatted prompt\n",
        "        \"\"\"\n",
        "        # Validate that all required variables are provided\n",
        "        for var in self.input_variables:\n",
        "            if var not in kwargs:\n",
        "                raise ValueError(f\"Missing required variable: {var}\")\n",
        "        \n",
        "        # Format the template\n",
        "        return self.template.format(**kwargs)\n",
        "    \n",
        "    def run(\n",
        "        self, \n",
        "        model: str = \"gemini-2.0-flash\", \n",
        "        temperature: float = 0,\n",
        "        **kwargs\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Format the template and get a completion.\n",
        "        \n",
        "        Args:\n",
        "            model: The model to use for completion\n",
        "            temperature: Controls randomness\n",
        "            **kwargs: The variables to substitute into the template\n",
        "            \n",
        "        Returns:\n",
        "            The model's response\n",
        "        \"\"\"\n",
        "        prompt = self.format(**kwargs)\n",
        "        response = get_completion(prompt, model=model, temperature=temperature)\n",
        "        \n",
        "        # Log the result\n",
        "        self.results.append({\n",
        "            \"prompt\": prompt,\n",
        "            \"response\": response,\n",
        "            \"model\": model,\n",
        "            \"temperature\": temperature,\n",
        "            \"variables\": kwargs\n",
        "        })\n",
        "        \n",
        "        return response\n",
        "    \n",
        "    def get_results_df(self) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Return the results as a DataFrame.\n",
        "        \n",
        "        Returns:\n",
        "            DataFrame containing all results\n",
        "        \"\"\"\n",
        "        return pd.DataFrame(self.results)\n",
        "\n",
        "# Dictionary to store and compare different prompt templates\n",
        "prompt_templates = {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_prompts(\n",
        "    templates: Dict[str, PromptTemplate], \n",
        "    eval_data: List[Dict],\n",
        "    metrics: List[str] = [\"correctness\", \"relevance\", \"clarity\"]\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Evaluate multiple prompt templates on the same evaluation data.\n",
        "    \n",
        "    Args:\n",
        "        templates: Dictionary of prompt templates to evaluate\n",
        "        eval_data: List of test cases to run\n",
        "        metrics: List of metrics to evaluate\n",
        "        \n",
        "    Returns:\n",
        "        DataFrame with evaluation results\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    \n",
        "    for template_name, template in templates.items():\n",
        "        for i, data in enumerate(eval_data):\n",
        "            # Run the template on the test case\n",
        "            response = template.run(**data)\n",
        "            \n",
        "            # Add result entry\n",
        "            result = {\n",
        "                \"template_name\": template_name,\n",
        "                \"template_type\": template.template_type,\n",
        "                \"test_case\": i,\n",
        "                \"response\": response\n",
        "            }\n",
        "            \n",
        "            # Add placeholders for manual metrics\n",
        "            for metric in metrics:\n",
        "                result[f\"{metric}_score\"] = None\n",
        "                \n",
        "            results.append(result)\n",
        "    \n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "def manual_grade(df: pd.DataFrame, metric: str, row_index: int, score: int):\n",
        "    \"\"\"\n",
        "    Manually grade a response.\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame with evaluation results\n",
        "        metric: The metric to grade (e.g., \"correctness\")\n",
        "        row_index: Index of the row to grade\n",
        "        score: Score to assign (typically 1-5)\n",
        "    \"\"\"\n",
        "    df.at[row_index, f\"{metric}_score\"] = score\n",
        "    return df\n",
        "\n",
        "def visualize_results(df: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Visualize the evaluation results.\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame with evaluation results containing scores\n",
        "    \"\"\"\n",
        "    # Group by template type and calculate mean scores\n",
        "    metrics = [col for col in df.columns if col.endswith('_score')]\n",
        "    \n",
        "    if not metrics:\n",
        "        print(\"No metrics found in DataFrame\")\n",
        "        return\n",
        "        \n",
        "    grouped = df.groupby('template_type')[metrics].mean().reset_index()\n",
        "    \n",
        "    # Plot the results\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    \n",
        "    x = range(len(grouped['template_type']))\n",
        "    width = 0.8 / len(metrics)\n",
        "    \n",
        "    for i, metric in enumerate(metrics):\n",
        "        plt.bar([pos + i * width for pos in x], grouped[metric], \n",
        "                width=width, label=metric.replace('_score', ''))\n",
        "    \n",
        "    plt.xlabel('Prompt Template Type')\n",
        "    plt.ylabel('Average Score')\n",
        "    plt.title('Prompt Template Performance Comparison')\n",
        "    plt.xticks([pos + 0.4 - width/2 for pos in x], grouped['template_type'])\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    \n",
        "    return plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 1. Arithmetic Problems\n",
        "\n",
        "#Let's create prompt templates for solving arithmetic problems using different prompting techniques.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example using zero_shot_arithmetic:\n",
            "Problem: What is 123 + 456?\n",
            "Response: 123 + 456 = 579\n",
            "\n",
            "--------------------------------------------------\n",
            "Example using few_shot_arithmetic:\n",
            "Problem: What is 123 + 456?\n",
            "Response: 123 + 456 = 579\n",
            "\n",
            "--------------------------------------------------\n",
            "Example using few_shot_arithmetic:\n",
            "Problem: What is 123 + 456?\n",
            "Response: To solve 123 + 456, I add the numbers: 123 + 456 = 579\n",
            "\n",
            "--------------------------------------------------\n",
            "Example using cot_arithmetic:\n",
            "Problem: What is 123 + 456?\n",
            "Response: To solve 123 + 456, I add the numbers: 123 + 456 = 579\n",
            "\n",
            "--------------------------------------------------\n",
            "Example using cot_arithmetic:\n",
            "Problem: What is 123 + 456?\n",
            "Response: Okay, let's break down the addition problem 123 + 456 step-by-step:\n",
            "\n",
            "**1. Add the ones digits:**\n",
            "\n",
            "*   3 + 6 = 9\n",
            "\n",
            "**2. Add the tens digits:**\n",
            "\n",
            "*   2 + 5 = 7\n",
            "\n",
            "**3. Add the hundreds digits:**\n",
            "\n",
            "*   1 + 4 = 5\n",
            "\n",
            "**4. Combine the results:**\n",
            "\n",
            "*   We have 5 in the hundreds place, 7 in the tens place, and 9 in the ones place.\n",
            "\n",
            "**Therefore, 123 + 456 = 579**\n",
            "\n",
            "--------------------------------------------------\n",
            "Problem: What is 123 + 456?\n",
            "Response: Okay, let's break down the addition problem 123 + 456 step-by-step:\n",
            "\n",
            "**1. Add the ones digits:**\n",
            "\n",
            "*   3 + 6 = 9\n",
            "\n",
            "**2. Add the tens digits:**\n",
            "\n",
            "*   2 + 5 = 7\n",
            "\n",
            "**3. Add the hundreds digits:**\n",
            "\n",
            "*   1 + 4 = 5\n",
            "\n",
            "**4. Combine the results:**\n",
            "\n",
            "*   We have 5 in the hundreds place, 7 in the tens place, and 9 in the ones place.\n",
            "\n",
            "**Therefore, 123 + 456 = 579**\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Zero-shot prompting for arithmetic\n",
        "zero_shot_arithmetic = PromptTemplate(\n",
        "    template=\"Solve the following arithmetic problem: {problem}\",\n",
        "    input_variables=[\"problem\"],\n",
        "    template_type=\"zero-shot\"\n",
        ")\n",
        "\n",
        "# Few-shot prompting for arithmetic\n",
        "few_shot_arithmetic = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "Solve the following arithmetic problems:\n",
        "\n",
        "Problem: What is 15 + 27?\n",
        "Answer: To solve 15 + 27, I add the numbers: 15 + 27 = 42\n",
        "\n",
        "Problem: What is 8 × 12?\n",
        "Answer: To solve 8 × 12, I multiply the numbers: 8 × 12 = 96\n",
        "\n",
        "Problem: What is 99 - 45?\n",
        "Answer: To solve 99 - 45, I subtract 45 from 99: 99 - 45 = 54\n",
        "\n",
        "Problem: {problem}\n",
        "Answer:\n",
        "\"\"\",\n",
        "    input_variables=[\"problem\"],\n",
        "    template_type=\"few-shot\"\n",
        ")\n",
        "\n",
        "# Chain-of-thought prompting for arithmetic\n",
        "cot_arithmetic = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "Solve the following arithmetic problem by breaking it down into steps.\n",
        "\n",
        "Problem: {problem}\n",
        "\n",
        "Let me solve this step-by-step:\n",
        "\"\"\",\n",
        "    input_variables=[\"problem\"],\n",
        "    template_type=\"chain-of-thought\"\n",
        ")\n",
        "\n",
        "# Store the templates\n",
        "prompt_templates[\"zero_shot_arithmetic\"] = zero_shot_arithmetic\n",
        "prompt_templates[\"few_shot_arithmetic\"] = few_shot_arithmetic\n",
        "prompt_templates[\"cot_arithmetic\"] = cot_arithmetic\n",
        "\n",
        "# Test cases for arithmetic\n",
        "arithmetic_test_cases = [\n",
        "    {\"problem\": \"What is 123 + 456?\"},\n",
        "    {\"problem\": \"If 7 people share 35 cookies equally, how many cookies does each person get?\"},\n",
        "    {\"problem\": \"Calculate 15% of 240.\"}\n",
        "]\n",
        "\n",
        "# We'll run the evaluation and show examples of each prompting technique\n",
        "for template_name, template in prompt_templates.items():\n",
        "    if \"arithmetic\" in template_name:\n",
        "        print(f\"Example using {template_name}:\")\n",
        "        response = template.run(**arithmetic_test_cases[0])\n",
        "        print(f\"Problem: {arithmetic_test_cases[0]['problem']}\")\n",
        "        print(f\"Response: {response}\")\n",
        "        print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. Text Rephrasing\n",
        "\n",
        "#Creating prompt templates for rephrasing text using different prompting techniques.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example using zero_shot_rephrase:\n",
            "Original: The company has decided to implement a new policy starting next month.\n",
            "Style: formal\n",
            "Rephrased: Here are a few options for a more formal rephrasing, with slight variations in tone:\n",
            "\n",
            "*   **Effective next month, the company will implement a new policy.** (Direct and concise)\n",
            "*   **The company has resolved to implement a new policy, commencing next month.** (More formal vocabulary)\n",
            "*   **A new policy will be implemented by the company, effective the beginning of next month.** (Passive voice, emphasizes the policy)\n",
            "*   **The company has determined to implement a new policy, with an effective date of next month.** (Slightly more elaborate)\n",
            "*   **Please be advised that the company will be implementing a new policy, effective next month.** (Adds a polite introduction)\n",
            "\n",
            "--------------------------------------------------\n",
            "Example using few_shot_rephrase:\n",
            "Original: The company has decided to implement a new policy starting next month.\n",
            "Style: formal\n",
            "Rephrased: Here are a few options for a more formal rephrasing, with slight variations in tone:\n",
            "\n",
            "*   **Effective next month, the company will implement a new policy.** (Direct and concise)\n",
            "*   **The company has resolved to implement a new policy, commencing next month.** (More formal vocabulary)\n",
            "*   **A new policy will be implemented by the company, effective the beginning of next month.** (Passive voice, emphasizes the policy)\n",
            "*   **The company has determined to implement a new policy, with an effective date of next month.** (Slightly more elaborate)\n",
            "*   **Please be advised that the company will be implementing a new policy, effective next month.** (Adds a polite introduction)\n",
            "\n",
            "--------------------------------------------------\n",
            "Example using few_shot_rephrase:\n",
            "Original: The company has decided to implement a new policy starting next month.\n",
            "Style: formal\n",
            "Rephrased: Here are a few options for a more formal rephrasing of \"The company has decided to implement a new policy starting next month,\" with slightly different nuances:\n",
            "\n",
            "**Option 1 (Focus on the decision):**\n",
            "\n",
            "*   The organization has resolved to institute a novel policy, effective commencing next month.\n",
            "\n",
            "**Option 2 (Focus on the implementation):**\n",
            "\n",
            "*   The implementation of a revised policy by the company is scheduled to commence next month.\n",
            "\n",
            "**Option 3 (More direct and concise):**\n",
            "\n",
            "*   The company has determined to enact a new policy, with implementation scheduled for the subsequent month.\n",
            "\n",
            "**Option 4 (Emphasizing the official nature):**\n",
            "\n",
            "*   The company has officially resolved to implement a new policy, effective the following month.\n",
            "\n",
            "The best option depends on the specific context and the desired level of formality. All of them are more formal than the original.\n",
            "\n",
            "--------------------------------------------------\n",
            "Example using cot_rephrase:\n",
            "Original: The company has decided to implement a new policy starting next month.\n",
            "Style: formal\n",
            "Rephrased: Here are a few options for a more formal rephrasing of \"The company has decided to implement a new policy starting next month,\" with slightly different nuances:\n",
            "\n",
            "**Option 1 (Focus on the decision):**\n",
            "\n",
            "*   The organization has resolved to institute a novel policy, effective commencing next month.\n",
            "\n",
            "**Option 2 (Focus on the implementation):**\n",
            "\n",
            "*   The implementation of a revised policy by the company is scheduled to commence next month.\n",
            "\n",
            "**Option 3 (More direct and concise):**\n",
            "\n",
            "*   The company has determined to enact a new policy, with implementation scheduled for the subsequent month.\n",
            "\n",
            "**Option 4 (Emphasizing the official nature):**\n",
            "\n",
            "*   The company has officially resolved to implement a new policy, effective the following month.\n",
            "\n",
            "The best option depends on the specific context and the desired level of formality. All of them are more formal than the original.\n",
            "\n",
            "--------------------------------------------------\n",
            "Example using cot_rephrase:\n",
            "Original: The company has decided to implement a new policy starting next month.\n",
            "Style: formal\n",
            "Rephrased: Okay, here's a more formal rephrasing of the original text, keeping in mind the elements of formality you outlined:\n",
            "\n",
            "**Formal Rephrasing:**\n",
            "\n",
            "\"The company has resolved to implement a revised policy, effective commencing next month.\"\n",
            "\n",
            "**Explanation of Changes and Why They're More Formal:**\n",
            "\n",
            "*   **\"Resolved to implement\"** replaces \"has decided to implement.\" \"Resolved\" carries a stronger sense of official decision-making.\n",
            "*   **\"Revised policy\"** replaces \"new policy.\" While \"new\" isn't inherently informal, \"revised\" suggests a more considered and potentially updated approach. If it's *truly* a brand new policy, you could use \"a novel policy\" but \"revised\" is generally safer.\n",
            "*   **\"Effective commencing next month\"** replaces \"starting next month.\" This is the most significant shift in formality. \"Effective commencing\" is a more traditional and business-like phrase.\n",
            "\n",
            "Other options, depending on the specific context and desired level of formality, could include:\n",
            "\n",
            "*   \"The company has determined that a new policy will be implemented...\"\n",
            "*   \"Management has approved the implementation of a new policy...\"\n",
            "*   \"The company will institute a new policy, effective...\"\n",
            "\n",
            "The best choice will depend on the specific context and the audience you are addressing.\n",
            "\n",
            "--------------------------------------------------\n",
            "Original: The company has decided to implement a new policy starting next month.\n",
            "Style: formal\n",
            "Rephrased: Okay, here's a more formal rephrasing of the original text, keeping in mind the elements of formality you outlined:\n",
            "\n",
            "**Formal Rephrasing:**\n",
            "\n",
            "\"The company has resolved to implement a revised policy, effective commencing next month.\"\n",
            "\n",
            "**Explanation of Changes and Why They're More Formal:**\n",
            "\n",
            "*   **\"Resolved to implement\"** replaces \"has decided to implement.\" \"Resolved\" carries a stronger sense of official decision-making.\n",
            "*   **\"Revised policy\"** replaces \"new policy.\" While \"new\" isn't inherently informal, \"revised\" suggests a more considered and potentially updated approach. If it's *truly* a brand new policy, you could use \"a novel policy\" but \"revised\" is generally safer.\n",
            "*   **\"Effective commencing next month\"** replaces \"starting next month.\" This is the most significant shift in formality. \"Effective commencing\" is a more traditional and business-like phrase.\n",
            "\n",
            "Other options, depending on the specific context and desired level of formality, could include:\n",
            "\n",
            "*   \"The company has determined that a new policy will be implemented...\"\n",
            "*   \"Management has approved the implementation of a new policy...\"\n",
            "*   \"The company will institute a new policy, effective...\"\n",
            "\n",
            "The best choice will depend on the specific context and the audience you are addressing.\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Zero-shot prompting for text rephrasing\n",
        "zero_shot_rephrase = PromptTemplate(\n",
        "    template=\"Rephrase the following text to make it more {style}: {text}\",\n",
        "    input_variables=[\"text\", \"style\"],\n",
        "    template_type=\"zero-shot\"\n",
        ")\n",
        "\n",
        "# Few-shot prompting for text rephrasing\n",
        "few_shot_rephrase = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "Here are examples of rephrasing text to make it more {style}:\n",
        "\n",
        "Original: The weather is not good today.\n",
        "{style} version: The meteorological conditions are rather unfavorable at present.\n",
        "\n",
        "Original: I like this book a lot.\n",
        "{style} version: I find this literary work exceedingly appealing.\n",
        "\n",
        "Original: We need to finish this project soon.\n",
        "{style} version: It is imperative that we complete this undertaking in the near future.\n",
        "\n",
        "Now, please rephrase the following text to make it more {style}:\n",
        "{text}\n",
        "\"\"\",\n",
        "    input_variables=[\"text\", \"style\"],\n",
        "    template_type=\"few-shot\"\n",
        ")\n",
        "\n",
        "# Chain-of-thought prompting for text rephrasing\n",
        "cot_rephrase = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "I need to rephrase the following text to make it more {style}.\n",
        "\n",
        "Original text: {text}\n",
        "\n",
        "Let me think about how to rephrase this:\n",
        "1. First, I'll identify the key points and message in the original text.\n",
        "2. Then I'll consider what makes text \"{style}\" - what vocabulary, tone, and structure to use.\n",
        "3. Finally, I'll rewrite the text using those elements while preserving the original meaning.\n",
        "\n",
        "My {style} rephrasing:\n",
        "\"\"\",\n",
        "    input_variables=[\"text\", \"style\"],\n",
        "    template_type=\"chain-of-thought\"\n",
        ")\n",
        "\n",
        "# Store the templates\n",
        "prompt_templates[\"zero_shot_rephrase\"] = zero_shot_rephrase\n",
        "prompt_templates[\"few_shot_rephrase\"] = few_shot_rephrase\n",
        "prompt_templates[\"cot_rephrase\"] = cot_rephrase\n",
        "\n",
        "# Test cases for rephrasing\n",
        "rephrase_test_cases = [\n",
        "    {\n",
        "        \"text\": \"The company has decided to implement a new policy starting next month.\",\n",
        "        \"style\": \"formal\"\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"This movie wasn't very good and I wouldn't recommend it.\",\n",
        "        \"style\": \"positive\"\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"The research shows that diet affects health outcomes.\",\n",
        "        \"style\": \"academic\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Example of each prompting technique for rephrasing\n",
        "for template_name, template in prompt_templates.items():\n",
        "    if \"rephrase\" in template_name:\n",
        "        print(f\"Example using {template_name}:\")\n",
        "        response = template.run(**rephrase_test_cases[0])\n",
        "        print(f\"Original: {rephrase_test_cases[0]['text']}\")\n",
        "        print(f\"Style: {rephrase_test_cases[0]['style']}\")\n",
        "        print(f\"Rephrased: {response}\")\n",
        "        print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 3. Content Summarization\n",
        "\n",
        "#Creating prompt templates for summarizing content using different prompting techniques.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example using zero_shot_summarize:\n",
            "Original length: 144 words\n",
            "Target length: 50 words\n",
            "Summary: Machine learning, a branch of AI, automates analytical model building by enabling systems to learn from data, identify patterns, and make decisions with minimal human intervention. Algorithms are either supervised, requiring labeled data, or unsupervised, using deep learning to find patterns independently.\n",
            "\n",
            "Summary length: 42 words\n",
            "--------------------------------------------------\n",
            "Example using few_shot_summarize:\n",
            "Original length: 144 words\n",
            "Target length: 50 words\n",
            "Summary: Machine learning, a branch of AI, automates analytical model building by enabling systems to learn from data, identify patterns, and make decisions with minimal human intervention. Algorithms are either supervised, requiring labeled data, or unsupervised, using deep learning to find patterns independently.\n",
            "\n",
            "Summary length: 42 words\n",
            "--------------------------------------------------\n",
            "Example using few_shot_summarize:\n",
            "Original length: 144 words\n",
            "Target length: 50 words\n",
            "Summary: Machine learning, a branch of AI, automates analytical model building by enabling systems to learn from data, identify patterns, and make decisions with minimal human intervention. Algorithms adapt as they are exposed to new data. They are categorized as supervised, requiring input and feedback, or unsupervised, using deep learning.\n",
            "\n",
            "Summary length: 49 words\n",
            "--------------------------------------------------\n",
            "Example using cot_summarize:\n",
            "Original length: 144 words\n",
            "Target length: 50 words\n",
            "Summary: Machine learning, a branch of AI, automates analytical model building by enabling systems to learn from data, identify patterns, and make decisions with minimal human intervention. Algorithms adapt as they are exposed to new data. They are categorized as supervised, requiring input and feedback, or unsupervised, using deep learning.\n",
            "\n",
            "Summary length: 49 words\n",
            "--------------------------------------------------\n",
            "Example using cot_summarize:\n",
            "Original length: 144 words\n",
            "Target length: 50 words\n",
            "Summary: Machine learning, a branch of AI, automates analytical model building by learning from data and identifying patterns with minimal human intervention. Models adapt iteratively to new data, producing reliable results. Algorithms are categorized as supervised (requiring input/output data) or unsupervised (using deep learning).\n",
            "\n",
            "Summary length: 43 words\n",
            "--------------------------------------------------\n",
            "Original length: 144 words\n",
            "Target length: 50 words\n",
            "Summary: Machine learning, a branch of AI, automates analytical model building by learning from data and identifying patterns with minimal human intervention. Models adapt iteratively to new data, producing reliable results. Algorithms are categorized as supervised (requiring input/output data) or unsupervised (using deep learning).\n",
            "\n",
            "Summary length: 43 words\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Zero-shot prompting for summarization\n",
        "zero_shot_summarize = PromptTemplate(\n",
        "    template=\"Summarize the following text in {word_count} words or less: {text}\",\n",
        "    input_variables=[\"text\", \"word_count\"],\n",
        "    template_type=\"zero-shot\"\n",
        ")\n",
        "\n",
        "# Few-shot prompting for summarization\n",
        "few_shot_summarize = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "Here are examples of summarizing text:\n",
        "\n",
        "Original text: The regulations on environmental protection were established to reduce pollution and conserve natural resources. They aim to balance economic growth with sustainable practices. The policy mandates that companies must report their emissions quarterly and invest in cleaner technologies.\n",
        "Summary (25 words): Environmental regulations aim to reduce pollution while balancing economic growth. Companies must report emissions and invest in clean technologies.\n",
        "\n",
        "Original text: The research study examined the effects of different exercise regimens on cardiovascular health in adults aged 40-60. Participants were divided into three groups: high-intensity interval training, moderate continuous exercise, and a control group. After six months, the high-intensity group showed the most significant improvements in heart rate variability and blood pressure.\n",
        "Summary (30 words): A six-month study comparing exercise types found high-intensity interval training produced better cardiovascular improvements than moderate exercise in adults aged 40-60.\n",
        "\n",
        "Now, summarize the following text in {word_count} words or less:\n",
        "{text}\n",
        "\"\"\",\n",
        "    input_variables=[\"text\", \"word_count\"],\n",
        "    template_type=\"few-shot\"\n",
        ")\n",
        "\n",
        "# Chain-of-thought prompting for summarization\n",
        "cot_summarize = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "I need to summarize the following text in {word_count} words or less.\n",
        "\n",
        "Text to summarize: {text}\n",
        "\n",
        "Let me approach this summarization process step by step:\n",
        "1. First, I'll identify the main topic and key points in the text.\n",
        "2. Then, I'll determine which details are essential and which can be omitted.\n",
        "3. Finally, I'll craft a concise summary using clear language while staying under the {word_count} word limit.\n",
        "\n",
        "My summary (within {word_count} words):\n",
        "\"\"\",\n",
        "    input_variables=[\"text\", \"word_count\"],\n",
        "    template_type=\"chain-of-thought\"\n",
        ")\n",
        "\n",
        "# Store the templates\n",
        "prompt_templates[\"zero_shot_summarize\"] = zero_shot_summarize\n",
        "prompt_templates[\"few_shot_summarize\"] = few_shot_summarize\n",
        "prompt_templates[\"cot_summarize\"] = cot_summarize\n",
        "\n",
        "# Test cases for summarization\n",
        "summarize_test_cases = [\n",
        "    {\n",
        "        \"text\": \"\"\"Machine learning is a method of data analysis that automates analytical model building. \n",
        "        It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns, \n",
        "        and make decisions with minimal human intervention. The iterative aspect of machine learning is important because \n",
        "        as models are exposed to new data, they are able to independently adapt. They learn from previous computations \n",
        "        to produce reliable, repeatable decisions and results. Machine learning algorithms are often categorized as supervised or unsupervised. \n",
        "        Supervised algorithms require a data scientist or data analyst with machine learning skills to provide both input and desired output, \n",
        "        in addition to furnishing feedback about the accuracy of predictions during algorithm training. Unsupervised algorithms do not need to be \n",
        "        trained with desired outcome data. Instead, they use an iterative approach called deep learning to review data and arrive at conclusions.\"\"\",\n",
        "        \"word_count\": 50\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"\"\"Climate change refers to significant, long-term changes in the global climate. \n",
        "        The global average surface temperature has increased over the last century. This is largely due to human activities, \n",
        "        particularly the burning of fossil fuels, which adds heat-trapping gases to Earth's atmosphere. The effects of human-caused \n",
        "        global warming are apparent and widespread. They include rising sea levels, ecosystem shifts, extreme weather events, \n",
        "        ocean acidification, and potential threats to human health and security. Addressing climate change will require adaptation \n",
        "        to already-occurring impacts and mitigation to reduce future warming. Internationally, the Paris Agreement aims to limit global warming \n",
        "        to well below 2 degrees Celsius above pre-industrial levels.\"\"\",\n",
        "        \"word_count\": 40\n",
        "    }\n",
        "]\n",
        "\n",
        "# Example of each prompting technique for summarization\n",
        "for template_name, template in prompt_templates.items():\n",
        "    if \"summarize\" in template_name:\n",
        "        print(f\"Example using {template_name}:\")\n",
        "        response = template.run(**summarize_test_cases[0])\n",
        "        print(f\"Original length: {len(summarize_test_cases[0]['text'].split())} words\")\n",
        "        print(f\"Target length: {summarize_test_cases[0]['word_count']} words\")\n",
        "        print(f\"Summary: {response}\")\n",
        "        print(f\"Summary length: {len(response.split())} words\")\n",
        "        print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4. Classification Tasks\n",
        "\n",
        "#Creating prompt templates for classification tasks using different prompting techniques.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example using zero_shot_classify:\n",
            "Content: I'm not sure if I like this product. It has some good features but also some issues.\n",
            "Categories: Positive, Negative, Neutral\n",
            "Classification: Neutral\n",
            "\n",
            "--------------------------------------------------\n",
            "Example using few_shot_classify:\n",
            "Content: I'm not sure if I like this product. It has some good features but also some issues.\n",
            "Categories: Positive, Negative, Neutral\n",
            "Classification: Neutral\n",
            "\n",
            "--------------------------------------------------\n",
            "Example using few_shot_classify:\n",
            "Content: I'm not sure if I like this product. It has some good features but also some issues.\n",
            "Categories: Positive, Negative, Neutral\n",
            "Classification: Neutral\n",
            "\n",
            "--------------------------------------------------\n",
            "Example using cot_classify:\n",
            "Content: I'm not sure if I like this product. It has some good features but also some issues.\n",
            "Categories: Positive, Negative, Neutral\n",
            "Classification: Neutral\n",
            "\n",
            "--------------------------------------------------\n",
            "Example using cot_classify:\n",
            "Content: I'm not sure if I like this product. It has some good features but also some issues.\n",
            "Categories: Positive, Negative, Neutral\n",
            "Classification: **1. Category Definitions:**\n",
            "\n",
            "*   **Positive:** Expresses satisfaction, approval, or enjoyment of the product.\n",
            "*   **Negative:** Expresses dissatisfaction, disapproval, or dislike of the product.\n",
            "*   **Neutral:** Expresses neither strong positive nor negative feelings; it might be informative or simply descriptive without a clear opinion.\n",
            "\n",
            "**2. Review Analysis:**\n",
            "\n",
            "The review states \"I'm not sure if I like this product.\" This indicates uncertainty and a lack of a strong positive or negative feeling. It also mentions \"some good features but also some issues,\" suggesting a mixed experience.\n",
            "\n",
            "**3. Category Determination:**\n",
            "\n",
            "Given the uncertainty and the mention of both positive and negative aspects, the review is best classified as **Neutral**.\n",
            "\n",
            "--------------------------------------------------\n",
            "Content: I'm not sure if I like this product. It has some good features but also some issues.\n",
            "Categories: Positive, Negative, Neutral\n",
            "Classification: **1. Category Definitions:**\n",
            "\n",
            "*   **Positive:** Expresses satisfaction, approval, or enjoyment of the product.\n",
            "*   **Negative:** Expresses dissatisfaction, disapproval, or dislike of the product.\n",
            "*   **Neutral:** Expresses neither strong positive nor negative feelings; it might be informative or simply descriptive without a clear opinion.\n",
            "\n",
            "**2. Review Analysis:**\n",
            "\n",
            "The review states \"I'm not sure if I like this product.\" This indicates uncertainty and a lack of a strong positive or negative feeling. It also mentions \"some good features but also some issues,\" suggesting a mixed experience.\n",
            "\n",
            "**3. Category Determination:**\n",
            "\n",
            "Given the uncertainty and the mention of both positive and negative aspects, the review is best classified as **Neutral**.\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Zero-shot prompting for classification\n",
        "zero_shot_classify = PromptTemplate(\n",
        "    template=\"Classify the following {content_type} into one of these categories: {categories}. Only respond with the category name.\\n\\n{content}\",\n",
        "    input_variables=[\"content\", \"categories\", \"content_type\"],\n",
        "    template_type=\"zero-shot\"\n",
        ")\n",
        "\n",
        "# Few-shot prompting for classification\n",
        "few_shot_classify = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "Here are some examples of {content_type} classification into these categories: {categories}\n",
        "\n",
        "Example 1: The customer service was excellent and the staff was very helpful.\n",
        "Category: Positive\n",
        "\n",
        "Example 2: The product arrived damaged and customer service didn't help at all.\n",
        "Category: Negative\n",
        "\n",
        "Example 3: It works as expected, but nothing special about it.\n",
        "Category: Neutral\n",
        "\n",
        "Now, classify the following {content_type} into one of these categories: {categories}. Only respond with the category name.\n",
        "\n",
        "{content}\n",
        "\"\"\",\n",
        "    input_variables=[\"content\", \"categories\", \"content_type\"],\n",
        "    template_type=\"few-shot\"\n",
        ")\n",
        "\n",
        "# Chain-of-thought prompting for classification\n",
        "cot_classify = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "I need to classify the following {content_type} into one of these categories: {categories}.\n",
        "\n",
        "{content_type} to classify: {content}\n",
        "\n",
        "Let me think about this step-by-step:\n",
        "1. First, I'll review what characterizes each category: {categories}.\n",
        "2. Then, I'll analyze the {content_type} to identify key elements that align with a specific category.\n",
        "3. Finally, I'll determine the most appropriate category.\n",
        "\n",
        "Based on my analysis, the category is:\n",
        "\"\"\",\n",
        "    input_variables=[\"content\", \"categories\", \"content_type\"],\n",
        "    template_type=\"chain-of-thought\"\n",
        ")\n",
        "\n",
        "# Store the templates\n",
        "prompt_templates[\"zero_shot_classify\"] = zero_shot_classify\n",
        "prompt_templates[\"few_shot_classify\"] = few_shot_classify\n",
        "prompt_templates[\"cot_classify\"] = cot_classify\n",
        "\n",
        "# Test cases for classification\n",
        "classify_test_cases = [\n",
        "    {\n",
        "        \"content\": \"I'm not sure if I like this product. It has some good features but also some issues.\",\n",
        "        \"categories\": \"Positive, Negative, Neutral\",\n",
        "        \"content_type\": \"product review\"\n",
        "    },\n",
        "    {\n",
        "        \"content\": \"Scientists discover new species of deep-sea fish that can survive extreme pressure.\",\n",
        "        \"categories\": \"Science, Politics, Entertainment, Sports, Technology\",\n",
        "        \"content_type\": \"news headline\"\n",
        "    },\n",
        "    {\n",
        "        \"content\": \"The company's revenue increased by 15% in the last quarter due to new product launches.\",\n",
        "        \"categories\": \"Financial Report, Marketing, Product Development, Human Resources\",\n",
        "        \"content_type\": \"business statement\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Example of each prompting technique for classification\n",
        "for template_name, template in prompt_templates.items():\n",
        "    if \"classify\" in template_name:\n",
        "        print(f\"Example using {template_name}:\")\n",
        "        response = template.run(**classify_test_cases[0])\n",
        "        print(f\"Content: {classify_test_cases[0]['content']}\")\n",
        "        print(f\"Categories: {classify_test_cases[0]['categories']}\")\n",
        "        print(f\"Classification: {response}\")\n",
        "        print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 5. Prompt Performance Evaluation\n",
        "\n",
        "Now let's run a comprehensive evaluation of our prompt templates and compare their performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running evaluations for all tasks...\n",
            "⚠️ Error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.0-flash', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '50s'}]}}. Retrying in 2 seconds...\n",
            "⚠️ Error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.0-flash', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '50s'}]}}. Retrying in 2 seconds...\n",
            "⚠️ Error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.0-flash', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}. Retrying in 2 seconds...\n",
            "⚠️ Error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.0-flash', 'location': 'global'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}. Retrying in 2 seconds...\n",
            "⚠️ Error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}. Retrying in 2 seconds...\n",
            "⚠️ Error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}. Retrying in 2 seconds...\n",
            "⚠️ Error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}. Retrying in 2 seconds...\n",
            "⚠️ Error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}. Retrying in 2 seconds...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 104\u001b[39m, in \u001b[36mget_completion\u001b[39m\u001b[34m(prompt, model, temperature, max_retries, retry_delay)\u001b[39m\n\u001b[32m    103\u001b[39m response_text = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerate_content_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_text\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/google/genai/models.py:6130\u001b[39m, in \u001b[36mModels.generate_content_stream\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   6126\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m1\u001b[39m:\n\u001b[32m   6127\u001b[39m   \u001b[38;5;66;03m# First request gets a function call.\u001b[39;00m\n\u001b[32m   6128\u001b[39m   \u001b[38;5;66;03m# Then get function response parts.\u001b[39;00m\n\u001b[32m   6129\u001b[39m   \u001b[38;5;66;03m# Yield chunks only if there's no function response parts.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6130\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   6131\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunction_map\u001b[49m\u001b[43m:\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/google/genai/models.py:5013\u001b[39m, in \u001b[36mModels._generate_content_stream\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5011\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m5013\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest_streamed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5014\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   5015\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   5017\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvertexai\u001b[49m\u001b[43m:\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/google/genai/_api_client.py:804\u001b[39m, in \u001b[36mBaseApiClient.request_streamed\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m    800\u001b[39m http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m    801\u001b[39m     http_method, path, request_dict, http_options\n\u001b[32m    802\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m804\u001b[39m session_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    805\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m session_response.segments():\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/google/genai/_api_client.py:702\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m    701\u001b[39m response = \u001b[38;5;28mself\u001b[39m._httpx_client.send(httpx_request, stream=stream)\n\u001b[32m--> \u001b[39m\u001b[32m702\u001b[39m \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m    704\u001b[39m     response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m    705\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/google/genai/errors.py:101\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n",
            "\u001b[31mClientError\u001b[39m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}, 'quotaValue': '15'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     40\u001b[39m summarize_results = evaluate_prompts(\n\u001b[32m     41\u001b[39m     summarize_templates, \n\u001b[32m     42\u001b[39m     summarize_test_cases,\n\u001b[32m     43\u001b[39m     metrics=[\u001b[33m\"\u001b[39m\u001b[33mconciseness\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcompleteness\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     44\u001b[39m )\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Classification evaluation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m classify_results = \u001b[43mevaluate_prompts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclassify_templates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclassify_test_cases\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maccuracy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconfidence\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEvaluations complete! You can now manually grade the results using the manual_grade function.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     54\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mExample: manual_grade(arithmetic_results, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcorrectness\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, 0, 5)\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mevaluate_prompts\u001b[39m\u001b[34m(templates, eval_data, metrics)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m template_name, template \u001b[38;5;129;01min\u001b[39;00m templates.items():\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(eval_data):\n\u001b[32m     21\u001b[39m         \u001b[38;5;66;03m# Run the template on the test case\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m         response = \u001b[43mtemplate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m         \u001b[38;5;66;03m# Add result entry\u001b[39;00m\n\u001b[32m     25\u001b[39m         result = {\n\u001b[32m     26\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtemplate_name\u001b[39m\u001b[33m\"\u001b[39m: template_name,\n\u001b[32m     27\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtemplate_type\u001b[39m\u001b[33m\"\u001b[39m: template.template_type,\n\u001b[32m     28\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtest_case\u001b[39m\u001b[33m\"\u001b[39m: i,\n\u001b[32m     29\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m: response\n\u001b[32m     30\u001b[39m         }\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mPromptTemplate.run\u001b[39m\u001b[34m(self, model, temperature, **kwargs)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[33;03mFormat the template and get a completion.\u001b[39;00m\n\u001b[32m     47\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m \u001b[33;03m    The model's response\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     56\u001b[39m prompt = \u001b[38;5;28mself\u001b[39m.format(**kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m response = \u001b[43mget_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Log the result\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[38;5;28mself\u001b[39m.results.append({\n\u001b[32m     61\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m: prompt,\n\u001b[32m     62\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m: response,\n\u001b[32m   (...)\u001b[39m\u001b[32m     65\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mvariables\u001b[39m\u001b[33m\"\u001b[39m: kwargs\n\u001b[32m     66\u001b[39m })\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 122\u001b[39m, in \u001b[36mget_completion\u001b[39m\u001b[34m(prompt, model, temperature, max_retries, retry_delay)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attempt < max_retries - \u001b[32m1\u001b[39m:\n\u001b[32m    121\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m⚠️ Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Retrying in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mretry_delay\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m❌ Error: Could not get completion from API: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Set up dictionaries for each task type\n",
        "arithmetic_templates = {\n",
        "    name: template for name, template in prompt_templates.items() \n",
        "    if \"arithmetic\" in name\n",
        "}\n",
        "\n",
        "rephrase_templates = {\n",
        "    name: template for name, template in prompt_templates.items() \n",
        "    if \"rephrase\" in name\n",
        "}\n",
        "\n",
        "summarize_templates = {\n",
        "    name: template for name, template in prompt_templates.items() \n",
        "    if \"summarize\" in name\n",
        "}\n",
        "\n",
        "classify_templates = {\n",
        "    name: template for name, template in prompt_templates.items() \n",
        "    if \"classify\" in name\n",
        "}\n",
        "\n",
        "# Run evaluations for each task type\n",
        "print(\"Running evaluations for all tasks...\")\n",
        "\n",
        "# Arithmetic evaluation\n",
        "arithmetic_results = evaluate_prompts(\n",
        "    arithmetic_templates, \n",
        "    arithmetic_test_cases,\n",
        "    metrics=[\"correctness\", \"clarity\", \"efficiency\"]\n",
        ")\n",
        "\n",
        "# Rephrasing evaluation\n",
        "rephrase_results = evaluate_prompts(\n",
        "    rephrase_templates, \n",
        "    rephrase_test_cases,\n",
        "    metrics=[\"style_adherence\", \"clarity\", \"creativity\"]\n",
        ")\n",
        "\n",
        "# Summarization evaluation\n",
        "summarize_results = evaluate_prompts(\n",
        "    summarize_templates, \n",
        "    summarize_test_cases,\n",
        "    metrics=[\"conciseness\", \"completeness\", \"accuracy\"]\n",
        ")\n",
        "\n",
        "# Classification evaluation\n",
        "classify_results = evaluate_prompts(\n",
        "    classify_templates, \n",
        "    classify_test_cases,\n",
        "    metrics=[\"accuracy\", \"confidence\", \"reasoning\"]\n",
        ")\n",
        "\n",
        "print(\"Evaluations complete! You can now manually grade the results using the manual_grade function.\")\n",
        "print(\"Example: manual_grade(arithmetic_results, 'correctness', 0, 5)\")\n",
        "\n",
        "# Combine all results\n",
        "all_results = pd.concat([\n",
        "    arithmetic_results, \n",
        "    rephrase_results, \n",
        "    summarize_results, \n",
        "    classify_results\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.figure(num: 'int | str | Figure | SubFigure | None' = None, figsize: 'tuple[float, float] | None' = None, dpi: 'float | None' = None, *, facecolor: 'ColorType | None' = None, edgecolor: 'ColorType | None' = None, frameon: 'bool' = True, FigureClass: 'type[Figure]' = <class 'matplotlib.figure.Figure'>, clear: 'bool' = False, **kwargs) -> 'Figure'>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Example of manual grading (you would grade each response in practice)\n",
        "# For demonstration purposes, we'll grade a few examples\n",
        "\n",
        "# Grade arithmetic results (simulating manual grading)\n",
        "for i in range(min(3, len(arithmetic_results))):\n",
        "    # Simulating scores based on template type - in real use, you would review responses and grade them\n",
        "    if \"zero_shot\" in arithmetic_results.iloc[i]['template_name']:\n",
        "        arithmetic_results = manual_grade(arithmetic_results, 'correctness', i, 3)\n",
        "        arithmetic_results = manual_grade(arithmetic_results, 'clarity', i, 2)\n",
        "        arithmetic_results = manual_grade(arithmetic_results, 'efficiency', i, 2)\n",
        "    elif \"few_shot\" in arithmetic_results.iloc[i]['template_name']:\n",
        "        arithmetic_results = manual_grade(arithmetic_results, 'correctness', i, 4)\n",
        "        arithmetic_results = manual_grade(arithmetic_results, 'clarity', i, 4)\n",
        "        arithmetic_results = manual_grade(arithmetic_results, 'efficiency', i, 3)\n",
        "    else:  # chain-of-thought\n",
        "        arithmetic_results = manual_grade(arithmetic_results, 'correctness', i, 5)\n",
        "        arithmetic_results = manual_grade(arithmetic_results, 'clarity', i, 5)\n",
        "        arithmetic_results = manual_grade(arithmetic_results, 'efficiency', i, 4)\n",
        "\n",
        "# Visualize the arithmetic results\n",
        "arithmetic_plot = visualize_results(arithmetic_results)\n",
        "arithmetic_plot.title(\"Arithmetic Prompt Performance\")\n",
        "display(arithmetic_plot.figure)\n",
        "\n",
        "# In a real evaluation, you would continue by grading all other task types:\n",
        "# - manual_grade(rephrase_results, ...)\n",
        "# - manual_grade(summarize_results, ...)\n",
        "# - manual_grade(classify_results, ...)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 6. Prompt Logs and Version Control\n",
        "\n",
        "#This section demonstrates how to log prompt templates and results for version control.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved templates to week_two/prompt_logs/templates_v1.json\n",
            "Saved results to week_two/prompt_logs/results_v1.csv\n",
            "Generated report at week_two/prompt_logs/report_v1.md\n"
          ]
        }
      ],
      "source": [
        "def save_prompt_logs(templates, results, version=\"v1\", path=\"prompt_logs\"):\n",
        "    \"\"\"\n",
        "    Save prompt templates and results to files for version control.\n",
        "    \n",
        "    Args:\n",
        "        templates: Dictionary of prompt templates\n",
        "        results: DataFrame with evaluation results\n",
        "        version: Version string\n",
        "        path: Directory to save logs\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import json\n",
        "    \n",
        "    # Create directory if it doesn't exist\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    \n",
        "    # Save templates\n",
        "    template_logs = {}\n",
        "    for name, template in templates.items():\n",
        "        template_logs[name] = {\n",
        "            \"template\": template.template,\n",
        "            \"input_variables\": template.input_variables,\n",
        "            \"template_type\": template.template_type\n",
        "        }\n",
        "    \n",
        "    with open(f\"{path}/templates_{version}.json\", \"w\") as f:\n",
        "        json.dump(template_logs, f, indent=2)\n",
        "    \n",
        "    # Save results\n",
        "    results_file = f\"{path}/results_{version}.csv\"\n",
        "    results.to_csv(results_file, index=False)\n",
        "    \n",
        "    print(f\"Saved templates to {path}/templates_{version}.json\")\n",
        "    print(f\"Saved results to {path}/results_{version}.csv\")\n",
        "    \n",
        "    # Generate report\n",
        "    report = f\"\"\"# Prompt Engineering Report {version}\n",
        "\n",
        "## Summary\n",
        "- Total templates: {len(templates)}\n",
        "- Total evaluations: {len(results)}\n",
        "- Template types: {', '.join(results['template_type'].unique())}\n",
        "\n",
        "## Tasks Evaluated\n",
        "- {', '.join(set([name.split('_')[-1] for name in templates.keys()]))}\n",
        "\"\"\"\n",
        "    \n",
        "    with open(f\"{path}/report_{version}.md\", \"w\") as f:\n",
        "        f.write(report)\n",
        "    \n",
        "    print(f\"Generated report at {path}/report_{version}.md\")\n",
        "\n",
        "# Create logs directory\n",
        "os.makedirs(\"week_two/prompt_logs\", exist_ok=True)\n",
        "\n",
        "# Save the prompt templates and evaluation results\n",
        "save_prompt_logs(\n",
        "    prompt_templates, \n",
        "    arithmetic_results,  # or use all_results if it is defined\n",
        "    version=\"v1\", \n",
        "    path=\"week_two/prompt_logs\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ## 8. Conclusion\n",
        "\n",
        "# This notebook has demonstrated:\n",
        "\n",
        "# 1. **Different prompting techniques**:\n",
        "#    - Zero-shot prompting: Direct instructions with no examples\n",
        "#    - Few-shot prompting: Including examples to guide the model\n",
        "#    - Chain-of-thought prompting: Encouraging step-by-step reasoning\n",
        "\n",
        "# 2. **Application across diverse tasks**:\n",
        "#    - Arithmetic problems\n",
        "#    - Text rephrasing\n",
        "#    - Content summarization\n",
        "#    - Classification\n",
        "\n",
        "# 3. **Structured approach to prompt engineering**:\n",
        "#    - Created a reusable `PromptTemplate` class\n",
        "#    - Implemented evaluation framework\n",
        "#    - Set up version control for prompt experiments\n",
        "\n",
        "# 4. **Key findings**:\n",
        "#    - Chain-of-thought prompting generally produces more detailed and accurate responses\n",
        "#    - Few-shot prompting is valuable for setting format expectations\n",
        "#    - Zero-shot works well for simple tasks but may lack consistency\n",
        "\n",
        "# For real-world applications, continue experimenting with different prompting strategies and adapt them to your specific use cases. Keep in mind that the effectiveness of each technique may vary depending on the model being used and the complexity of the task.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
